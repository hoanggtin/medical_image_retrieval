{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b8ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "dataset_path = \"D:\\\\Job\\\\image_retrieval\\\\data\\\\COVID-19_Radiography_Dataset\"\n",
    "structured_dataset = \"D:\\\\Job\\\\image_retrieval\\\\data\\\\COVID_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c96746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MedicalDataset, get_transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset_root = \"D:\\\\Job\\\\image_retrieval\\\\data\\\\COVID_Dataset\"\n",
    "\n",
    "full_dataset = MedicalDataset(dataset_root, transform=get_transforms())\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229e466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from config_cnn import Config\n",
    "from cnn_fpn_rmac import CNN_FPN_RMAC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "cfg = Config()\n",
    "cfg.NUM_CLASSES = 4  \n",
    "\n",
    "model = CNN_FPN_RMAC(cfg)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92270e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.6.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: d:\\app\\anaconda3\\envs\\mir_py310\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f92d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train     Loss: 0.6061 | Acc: 0.7628\n",
      "Val       Loss: 0.4054 | Acc: 0.8488\n",
      "✅ Saved best model at epoch 1 with val_acc 0.8488\n",
      "Epoch 2/100\n",
      "Train     Loss: 0.3599 | Acc: 0.8701\n",
      "Val       Loss: 0.3944 | Acc: 0.8538\n",
      "✅ Saved best model at epoch 2 with val_acc 0.8538\n",
      "Epoch 3/100\n",
      "Train     Loss: 0.2818 | Acc: 0.8974\n",
      "Val       Loss: 0.4074 | Acc: 0.8561\n",
      "✅ Saved best model at epoch 3 with val_acc 0.8561\n",
      "Epoch 4/100\n",
      "Train     Loss: 0.2399 | Acc: 0.9137\n",
      "Val       Loss: 0.3862 | Acc: 0.8651\n",
      "✅ Saved best model at epoch 4 with val_acc 0.8651\n",
      "Epoch 5/100\n",
      "Train     Loss: 0.2025 | Acc: 0.9272\n",
      "Val       Loss: 0.3145 | Acc: 0.8911\n",
      "✅ Saved best model at epoch 5 with val_acc 0.8911\n",
      "Epoch 6/100\n",
      "Train     Loss: 0.1802 | Acc: 0.9354\n",
      "Val       Loss: 0.2632 | Acc: 0.9024\n",
      "✅ Saved best model at epoch 6 with val_acc 0.9024\n",
      "Epoch 7/100\n",
      "Train     Loss: 0.1557 | Acc: 0.9442\n",
      "Val       Loss: 0.2263 | Acc: 0.9166\n",
      "✅ Saved best model at epoch 7 with val_acc 0.9166\n",
      "Epoch 8/100\n",
      "Train     Loss: 0.1276 | Acc: 0.9532\n",
      "Val       Loss: 0.2628 | Acc: 0.9031\n",
      "Epoch 9/100\n",
      "Train     Loss: 0.1089 | Acc: 0.9620\n",
      "Val       Loss: 0.2983 | Acc: 0.8909\n",
      "Epoch 10/100\n",
      "Train     Loss: 0.0809 | Acc: 0.9748\n",
      "Val       Loss: 0.2349 | Acc: 0.9202\n",
      "✅ Saved best model at epoch 10 with val_acc 0.9202\n",
      "Epoch 11/100\n",
      "Train     Loss: 0.0576 | Acc: 0.9821\n",
      "Val       Loss: 0.3079 | Acc: 0.9034\n",
      "Epoch 12/100\n",
      "Train     Loss: 0.0465 | Acc: 0.9855\n",
      "Val       Loss: 0.2634 | Acc: 0.9190\n",
      "Epoch 13/100\n",
      "Train     Loss: 0.0338 | Acc: 0.9905\n",
      "Val       Loss: 0.2895 | Acc: 0.9093\n",
      "Epoch 14/100\n",
      "Train     Loss: 0.0237 | Acc: 0.9943\n",
      "Val       Loss: 0.2711 | Acc: 0.9194\n",
      "Epoch 15/100\n",
      "Train     Loss: 0.0123 | Acc: 0.9982\n",
      "Val       Loss: 0.3366 | Acc: 0.9128\n",
      "Epoch 16/100\n",
      "Train     Loss: 0.0101 | Acc: 0.9982\n",
      "Val       Loss: 0.3238 | Acc: 0.9116\n",
      "Epoch 17/100\n",
      "Train     Loss: 0.0505 | Acc: 0.9826\n",
      "Val       Loss: 0.5038 | Acc: 0.8521\n",
      "Epoch 18/100\n",
      "Train     Loss: 0.0298 | Acc: 0.9908\n",
      "Val       Loss: 0.2969 | Acc: 0.9161\n",
      "Epoch 19/100\n",
      "Train     Loss: 0.0083 | Acc: 0.9985\n",
      "Val       Loss: 0.2889 | Acc: 0.9310\n",
      "✅ Saved best model at epoch 19 with val_acc 0.9310\n",
      "Epoch 20/100\n",
      "Train     Loss: 0.0020 | Acc: 1.0000\n",
      "Val       Loss: 0.2926 | Acc: 0.9317\n",
      "✅ Saved best model at epoch 20 with val_acc 0.9317\n",
      "Epoch 21/100\n",
      "Train     Loss: 0.0012 | Acc: 1.0000\n",
      "Val       Loss: 0.2965 | Acc: 0.9348\n",
      "✅ Saved best model at epoch 21 with val_acc 0.9348\n",
      "Epoch 22/100\n",
      "Train     Loss: 0.0009 | Acc: 1.0000\n",
      "Val       Loss: 0.3011 | Acc: 0.9317\n",
      "Epoch 23/100\n",
      "Train     Loss: 0.0007 | Acc: 1.0000\n",
      "Val       Loss: 0.3129 | Acc: 0.9341\n",
      "Epoch 24/100\n",
      "Train     Loss: 0.0007 | Acc: 1.0000\n",
      "Val       Loss: 0.3218 | Acc: 0.9331\n",
      "Epoch 25/100\n",
      "Train     Loss: 0.0006 | Acc: 1.0000\n",
      "Val       Loss: 0.3253 | Acc: 0.9336\n",
      "Epoch 26/100\n",
      "Train     Loss: 0.0004 | Acc: 1.0000\n",
      "Val       Loss: 0.3281 | Acc: 0.9331\n",
      "Epoch 27/100\n",
      "Train     Loss: 0.0004 | Acc: 1.0000\n",
      "Val       Loss: 0.3260 | Acc: 0.9282\n",
      "Epoch 28/100\n",
      "Train     Loss: 0.0003 | Acc: 1.0000\n",
      "Val       Loss: 0.3356 | Acc: 0.9329\n",
      "Epoch 29/100\n",
      "Train     Loss: 0.0002 | Acc: 1.0000\n",
      "Val       Loss: 0.3436 | Acc: 0.9324\n",
      "Epoch 30/100\n",
      "Train     Loss: 0.0367 | Acc: 0.9884\n",
      "Val       Loss: 0.9157 | Acc: 0.7666\n",
      "Epoch 31/100\n",
      "Train     Loss: 0.1402 | Acc: 0.9476\n",
      "Val       Loss: 0.3473 | Acc: 0.9027\n",
      "Epoch 32/100\n",
      "Train     Loss: 0.0401 | Acc: 0.9872\n",
      "Val       Loss: 0.3123 | Acc: 0.9062\n",
      "Epoch 33/100\n",
      "Train     Loss: 0.0151 | Acc: 0.9966\n",
      "Val       Loss: 0.3458 | Acc: 0.9050\n",
      "Epoch 34/100\n",
      "Train     Loss: 0.0101 | Acc: 0.9978\n",
      "Val       Loss: 0.2937 | Acc: 0.9277\n",
      "Epoch 35/100\n",
      "Train     Loss: 0.0084 | Acc: 0.9976\n",
      "Val       Loss: 0.3902 | Acc: 0.9046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     13\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32md:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32md:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32md:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32md:\\Job\\image_retrieval\\code\\dataset.py:38\u001b[0m, in \u001b[0;36mMedicalDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     37\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[idx]\n\u001b[1;32m---> 38\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[1;32md:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\PIL\\Image.py:982\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    980\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m--> 982\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32md:\\App\\anaconda3\\envs\\mir_py310\\lib\\site-packages\\PIL\\ImageFile.py:389\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    388\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 389\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "checkpoint_dir = \"D:\\\\Job\\\\image_retrieval\\\\models\\\\checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0.0, 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        train_correct += (outputs.argmax(1) == y).sum().item()\n",
    "\n",
    "    train_acc = train_correct / len(train_dataset)\n",
    "    train_loss /= len(train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_correct += (outputs.argmax(1) == y).sum().item()\n",
    "\n",
    "    val_acc = val_correct / len(val_dataset)\n",
    "    val_loss /= len(val_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/100\")\n",
    "    print(f\"Train     Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val       Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "    checkpoint_path = os.path.join(\n",
    "        checkpoint_dir, f\"epoch_{epoch+1:02d}_valacc_{val_acc:.4f}.pth\"\n",
    "    )\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_path = os.path.join(checkpoint_dir, \"best_cnn_model.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Saved best model at epoch {epoch+1} with val_acc {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41f553d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model_save_path = \"D:\\\\Job\\\\image_retrieval\\\\models\\\\covid_cnn_fpn_rmac.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mir_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
